# ad-icrl
Implementation of paper "In-context Reinforcement Learning with Algorithm Distillation"

## Installation üßë‚Äçüîß

```bash
git clone ...
cd ad-icrl
python -m venv venv
pip install -r requirements/requirements.txt
```
Set up environmental variable `PYTHONPATH`:

```bash
export PYTHONPATH=.
```

## Repository structure 

```text
.
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îú‚îÄ‚îÄ colab.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ config_paper.py  # hyperparams from paper
‚îÇ   ‚îú‚îÄ‚îÄ explore_dataset.ipynb  # overview the learning histories
‚îÇ   ‚îî‚îÄ‚îÄ test_dark_room.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements
‚îÇ   ‚îú‚îÄ‚îÄ requirements_colab.txt  # requirements for colab
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ saved_data
‚îÇ   ‚îú‚îÄ‚îÄ learning_history/
‚îÇ   ‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îú‚îÄ‚îÄ goals_9.txt
‚îÇ   ‚îî‚îÄ‚îÄ permutations_9.txt
‚îú‚îÄ‚îÄ scripts
‚îÇ   ‚îú‚îÄ‚îÄ collect_data.sh
‚îÇ   ‚îú‚îÄ‚îÄ eval.sh
‚îÇ   ‚îî‚îÄ‚îÄ train_ad.sh
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ check_in_context
‚îÇ   ‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ dt
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__
‚îú‚îÄ‚îÄ static
‚îÇ   ‚îú‚îÄ‚îÄ learning_histories_ppo-01.png
‚îÇ   ‚îú‚îÄ‚îÄ learning_histories_ppo-02.png
‚îÇ   ‚îú‚îÄ‚îÄ learning_histories_ppo-03.png
‚îÇ   ‚îú‚îÄ‚îÄ mean_eval_darkroom_13-Aug-15-09-45_299999_seed=0_mode.png
‚îÇ   ‚îú‚îÄ‚îÄ mean_eval_darkroom_13-Aug-15-09-45_299999_seed=0_sampling.png
‚îÇ   ‚îî‚îÄ‚îÄ mean_eval_darkroom_14-Aug-19-32-05_40000_seed=0.png
‚îî‚îÄ‚îÄ wandb
    ‚îú‚îÄ‚îÄ debug-internal.log -> run-20240815_132305-cl5uhidt/logs/debug-internal.log
    ‚îú‚îÄ‚îÄ debug.log -> run-20240815_132305-cl5uhidt/logs/debug.log
    ‚îú‚îÄ‚îÄ latest-run -> run-20240815_132305-cl5uhidt
    ‚îî‚îÄ‚îÄ run-20240815_132305-cl5uhidt
```


## Quick start üèÉ

### 0. init on wandb

...

### 1. Generate goals and permuations 

**or** use the provided file [saved_data/permutations_9.txt]().

```python
python src/data/generate_goals.py
```

### 2. Learn PPO agents to collect the dataset

**or** load the trajectories from gdrive via [link](https://drive.google.com/drive/folders/1_pExW9O4SoaraeDZCu05xageE2HBFj_d?usp=sharing).

Run the script to create the trajectories:

```python
chmod +x ./scripts/collect_data.sh
./scripts/collect_data.sh
```

The script will use `src/data/ppo.py` file. This script uses `wandb` logging, to disable it provide `--no-track` flag.

Observe the learning process on tensorboard:
```bash
tensorboard --logdir saved_data/logs/
```

### 3. Train AD


```bash
python src/dt/train.py
```